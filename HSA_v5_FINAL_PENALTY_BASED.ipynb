{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hospital Service Area (HSA) Optimization - v5.0 FINAL\n",
    "## Unified Scoring System with Mode-Specific Weight Profiles\n",
    "\n",
    "**Date**: 2025-11-27\n",
    "\n",
    "**Key Features**:\n",
    "- **Unified scoring system**: Single formula for all modes with mode-specific weight profiles\n",
    "- **Volume-based radius assignment**: Larger facilities get larger radii (0.8x to 1.2x multiplier)\n",
    "- **Composite score tracking**: All modes track and export composite scores\n",
    "- **Overlap removal**: All modes include post-processing to remove HSAs with >80% overlap\n",
    "- **Configurable parameters**: All key parameters set in notebook (not in .py file)\n",
    "\n",
    "## Five Optimization Modes\n",
    "\n",
    "### 1. FEWEST (Minimize number of HSAs)\n",
    "**Goal**: Achieve coverage with minimum facilities\n",
    "**Stopping**: 90% coverage\n",
    "**Expected**: 10-20 HSAs\n",
    "\n",
    "**Scoring Formula**:\n",
    "```\n",
    "composite_score =\n",
    "    WEIGHT_COVERAGE * coverage_norm * 2.0           # Coverage gain (high priority)\n",
    "  + WEIGHT_PATIENT_VOLUME * patient_norm * 1.5      # Facility size (high reward)\n",
    "  - WEIGHT_OVERLAP_PENALTY * overlap_frac * 1.0     # Redundancy penalty\n",
    "  + WEIGHT_CLIMATE * climate_norm * 1.0             # Geographic diversity\n",
    "  + WEIGHT_COVERAGE_PROGRESS * progress_norm * 0.0  # Progress disabled\n",
    "```\n",
    "\n",
    "**Rationale**: Prioritizes large, high-impact facilities that maximize coverage with minimal overlap. Zero progress weight prevents adding small facilities just to reach target.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. FOOTPRINT (Maximize geographic spread)\n",
    "**Goal**: Maximize population reached and geographic coverage\n",
    "**Stopping**: 90% coverage\n",
    "**Expected**: 25-35 HSAs\n",
    "\n",
    "**Scoring Formula**:\n",
    "```\n",
    "composite_score =\n",
    "    WEIGHT_COVERAGE * coverage_norm * 1.0           # Coverage gain (normal)\n",
    "  + WEIGHT_PATIENT_VOLUME * patient_norm * 1.0      # Facility size (normal)\n",
    "  - WEIGHT_OVERLAP_PENALTY * overlap_frac * 0.3     # Reduced overlap penalty\n",
    "  + WEIGHT_CLIMATE * climate_norm * 1.0             # Geographic diversity\n",
    "  + WEIGHT_COVERAGE_PROGRESS * progress_norm * 1.0  # Progress toward target\n",
    "```\n",
    "\n",
    "**Rationale**: Balanced weights allow broader geographic distribution. Low overlap penalty permits more facilities in populated areas to maximize reach.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. DISTANCE (Minimize travel distance)\n",
    "**Goal**: Minimize average travel distance to facilities\n",
    "**Stopping**: 90% coverage\n",
    "**Expected**: 10-20 HSAs\n",
    "\n",
    "**Scoring Formula**:\n",
    "```\n",
    "composite_score =\n",
    "    WEIGHT_COVERAGE * coverage_norm * 1.5           # Coverage gain (high)\n",
    "  + WEIGHT_PATIENT_VOLUME * patient_norm * 1.0      # Facility size (normal)\n",
    "  - WEIGHT_OVERLAP_PENALTY * overlap_frac * 0.8     # Moderate overlap penalty\n",
    "  + WEIGHT_CLIMATE * climate_norm * 1.0             # Geographic diversity\n",
    "  + WEIGHT_COVERAGE_PROGRESS * progress_norm * 1.0  # Progress toward target\n",
    "  - WEIGHT_DISTANCE_PENALTY * distance_norm * 1.0   # Travel distance penalty (unique to this mode)\n",
    "```\n",
    "\n",
    "**Rationale**: Only mode with distance penalty. Penalizes facilities far from population centers, encouraging selection of geographically central facilities.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. GOVERNORATE_TAU_COVERAGE (TAU method per governorate)\n",
    "**Goal**: Achieve 60% coverage in each governorate independently\n",
    "**Stopping**: TAU threshold met in all governorates\n",
    "**Expected**: 18-25 HSAs\n",
    "\n",
    "**Scoring Formula**: Same as FOOTPRINT (balanced approach per governorate)\n",
    "\n",
    "**Rationale**: Ensures geographic equity by guaranteeing minimum coverage in each administrative region, regardless of population density.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. GOVERNORATE_FEWEST (One anchor per governorate + FEWEST)\n",
    "**Goal**: Guarantee coverage in each governorate, then minimize total HSAs\n",
    "**Stopping**: 90% coverage with at least 1 HSA per governorate\n",
    "**Expected**: 12-20 HSAs\n",
    "\n",
    "**Scoring Formula**: Same as FEWEST (minimize facilities)\n",
    "\n",
    "**Rationale**: Combines administrative equity (1 HSA/governorate minimum) with efficiency (FEWEST scoring). Ensures no governorate is left without a facility.\n",
    "\n",
    "---\n",
    "\n",
    "## Base Weights (Configurable in Cell 4)\n",
    "\n",
    "These weights are applied to normalized 0-1 components, then multiplied by mode-specific profiles above:\n",
    "\n",
    "- `WEIGHT_COVERAGE = 5.0` (population coverage gain)\n",
    "- `WEIGHT_PATIENT_VOLUME = 7.0` (facility size reward)\n",
    "- `WEIGHT_OVERLAP_PENALTY = 3.0` (redundancy penalty)\n",
    "- `WEIGHT_CLIMATE = 1.0` (climate/geographic diversity)\n",
    "- `WEIGHT_COVERAGE_PROGRESS = 0.5` (progress toward target)\n",
    "- `WEIGHT_DISTANCE_PENALTY = 0.0` (travel distance penalty - only used in DISTANCE mode)\n",
    "\n",
    "## Radius Assignment\n",
    "\n",
    "1. Compute local population density (10km radius)\n",
    "2. Classify urban (>1500 people/km²) vs rural\n",
    "3. Assign base radius: Urban=12km, Rural=28km\n",
    "4. **Apply patient volume scaling**: 0.8x (small) to 1.2x (large)\n",
    "5. Apply network multiplier: INF=1.15x, NCD=1.0x\n",
    "6. Final radius range: ~11-39 km\n",
    "\n",
    "**Result**: Larger hospitals serve larger catchment areas (16+ unique radii, not just 2!)\n",
    "\n",
    "---\n",
    "\n",
    "## Normalization Details\n",
    "\n",
    "All scoring components normalized to 0-1 range:\n",
    "- **coverage_norm** = new_coverage / total_population\n",
    "- **patient_norm** = facility_volume / max_volume\n",
    "- **overlap_frac** = overlap_population / total_coverage (already 0-1)\n",
    "- **climate_norm** = 1 / (1 + unique_climate_clusters)\n",
    "- **progress_norm** = coverage_gain / remaining_to_target\n",
    "- **distance_norm** = mean_distance / max_distance\n",
    "\n",
    "---\n",
    "\n",
    "See cells below for configuration, execution, and analysis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# COMPREHENSIVE CONFIGURATION - ALL PARAMETERS\n",
    "# ============================================================================\n",
    "\n",
    "# Import Path for file paths (needed in this cell)\n",
    "from pathlib import Path\n",
    "\n",
    "# --- File Paths ---\n",
    "DATA_DIR = Path(\"data\")\n",
    "OUT_DIR = Path(\"out\")\n",
    "NETWORK = \"INF\"\n",
    "\n",
    "# --- Core Algorithm Parameters ---\n",
    "TAU_COVERAGE = 0.95                    # Maximum target coverage (95% - raised to differentiate modes)\n",
    "MAX_RADIUS_KM = 25                     # Absolute maximum radius (clinical requirement)\n",
    "RNG_SEED = 42                          # Random seed\n",
    "\n",
    "# --- Computational Efficiency ---\n",
    "BUFFER_KM = 30                         # Spatial crop buffer\n",
    "COARSEN_FACTOR = 10                    # Grid coarsening factor (use 4 for higher precision)\n",
    "\n",
    "# --- Density-Based Classification ---\n",
    "DENSITY_RADIUS_KM = 10.0               # FIXED 10km radius for density calculation\n",
    "URBAN_DENSITY_THRESH = 1500.0          # Urban if density > this (people/km²)\n",
    "\n",
    "# --- Base Radii ---\n",
    "# Balanced radii to give scoring model granularity while maintaining reasonable coverage\n",
    "URBAN_BASE_RADIUS_KM = 12.0            # Base radius for urban facilities\n",
    "RURAL_BASE_RADIUS_KM = 20.0            # Base radius for rural facilities\n",
    "\n",
    "# --- HSA Count Targets ---\n",
    "TARGET_HSA_MIN = 15                    # Minimum desired HSAs (for FEWEST mode floor)\n",
    "TARGET_HSA_MAX = 28                    # Maximum desired HSAs\n",
    "\n",
    "# --- Volume-Based Scoring ---\n",
    "VOLUME_WEIGHT = 1.5                    # Multiplier for patient volume in scoring function\n",
    "\n",
    "# --- Network-Specific Multipliers ---\n",
    "NETWORK_RADIUS_MULTIPLIERS = {\n",
    "    'INF': 1.0,   # Removed multiplier to keep radii in clinical target range\n",
    "    'NCD': 1.0,   # Non-communicable disease (baseline)\n",
    "}\n",
    "\n",
    "# --- Patient Volume Scaling ---\n",
    "PATIENT_RADIUS_ALPHA = 0.35            # Scaling strength for patient volume\n",
    "\n",
    "# --- Climate Diversity (applies to ALL objectives) ---\n",
    "CLIMATE_DIVERSITY_ON = True\n",
    "CLIMATE_K = 8\n",
    "CLIMATE_MIN_PER_CLUSTER = 1            # hard floor per climate bin (set 0 to disable)\n",
    "CLIMATE_CLUSTER_COL = \"climate_k\"      # column with precomputed cluster per facility\n",
    "CLIMATE_CSV = {\n",
    "    \"INF\": DATA_DIR / \"INF_Hospitals_Climate_Features_with_clusters.csv\",\n",
    "    \"NCD\": DATA_DIR / \"NCD_Hospitals_Climate_Features_with_clusters.csv\",\n",
    "}\n",
    "\n",
    "\n",
    "# --- Scoring Weights (0-10 scale, applied to normalized 0-1 components) ---\n",
    "# These are the baseline weights, modified by mode-specific profiles below\n",
    "WEIGHT_COVERAGE = 8.0                  # NEW population coverage (DOMINANT factor)\n",
    "WEIGHT_OVERLAP_PENALTY = 2.0           # Penalty for redundant coverage\n",
    "WEIGHT_CLIMATE = 1.0                   # Reward for climate/geographic diversity\n",
    "WEIGHT_PATIENT_VOLUME = 3.0            # Reward for larger patient volumes\n",
    "WEIGHT_COVERAGE_PROGRESS = 1.0         # Reward for approaching coverage target\n",
    "WEIGHT_DISTANCE_PENALTY = 3.0          # Penalty for average travel distance\n",
    "\n",
    "# Aliases for backward compatibility\n",
    "COVERAGE_WEIGHT = WEIGHT_COVERAGE\n",
    "LAMBDA_CLIMATE = WEIGHT_CLIMATE\n",
    "LAMBDA_PATIENT_VOLUME = WEIGHT_PATIENT_VOLUME\n",
    "\n",
    "# --- Mode-Specific Weight Profiles ---\n",
    "# Each mode applies multipliers to the base weights above\n",
    "MODE_WEIGHT_PROFILES = {\n",
    "    'fewest': {\n",
    "        'coverage': 1.5,           # Moderate coverage multiplier\n",
    "        'coverage_progress': 0.0,  # NO progress reward (stop immediately at 95%)\n",
    "        'overlap': 0.5,            # Low overlap penalty\n",
    "        'patient_volume': 2.5,     # Very high patient volume preference\n",
    "        'distance': 0.0,           # No distance penalty\n",
    "    },\n",
    "    'footprint': {\n",
    "        'coverage': 1.0,           # Standard coverage gain\n",
    "        'coverage_progress': 8.0,  # VERY STRONG progress reward (keep selecting to ~100%)\n",
    "        'overlap': 0.01,           # Almost no overlap penalty\n",
    "        'patient_volume': 0.05,    # Almost zero patient volume preference\n",
    "        'distance': 0.0,           # No distance penalty\n",
    "    },\n",
    "    'distance': {\n",
    "        'coverage': 1.0,           # Standard coverage gain\n",
    "        'coverage_progress': 6.0,  # Strong progress reward\n",
    "        'overlap': 0.02,           # Almost no overlap penalty\n",
    "        'patient_volume': 0.08,    # Very low patient volume preference\n",
    "        'distance': 2.5,           # Strong distance penalty (minimize avg distance)\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "# --- Optimization Modes to Run ---\n",
    "# Enable/disable specific optimization modes\n",
    "RUN_OBJECTIVES = {\n",
    "    'fewest': True,                      # Minimize number of HSAs\n",
    "    'footprint': True,                   # Maximize geographic spread\n",
    "    'distance': True,                    # Minimize travel distance\n",
    "    'governorate_tau_coverage': True,    # TAU method per governorate\n",
    "    'governorate_fewest': True           # One anchor per governorate + FEWEST\n",
    "}\n",
    "\n",
    "# --- HSAOptimizer configuration dict ---\n",
    "config = {\n",
    "    'pop_path': str(DATA_DIR / 'jor_ppp_2020_constrained.tif'),\n",
    "    'tau_coverage': 0.60,  # Used for GOVERNORATE_TAU_COVERAGE mode only\n",
    "    'coarsen': 4,  # Coarsen raster by 4x for speed (use 1 for full resolution)\n",
    "}\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"CONFIGURATION LOADED\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Network: {NETWORK}\")\n",
    "print(f\"Coverage target (TAU_COVERAGE): {TAU_COVERAGE*100:.0f}%\")\n",
    "print(f\"Governorate mode coverage: {config['tau_coverage']*100:.0f}%\")\n",
    "print(f\"Coarsen factor: {config['coarsen']}x\")\n",
    "print(f\"Urban base radius: {URBAN_BASE_RADIUS_KM} km\")\n",
    "print(f\"Rural base radius: {RURAL_BASE_RADIUS_KM} km\")\n",
    "print(f\"Max radius: {MAX_RADIUS_KM} km\")\n",
    "print(f\"Climate diversity: {CLIMATE_DIVERSITY_ON}\")\n",
    "print(f\"Target HSA range: {TARGET_HSA_MIN}-{TARGET_HSA_MAX}\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mode-Specific Optimization SettingsThe optimization now uses \n",
    "\n",
    "**mode-specific stopping conditions** to differentiate facility counts:\n",
    "\n",
    "### Stopping Logic:- \n",
    "\n",
    "**FEWEST**: Stops at 90% coverage with minimum 15 facilities  - Goal: Minimize number of facilities while meeting coverage target-\n",
    "**FOOTPRINT**: Continues to 22 facilities or 98% coverage  - Goal: Maximize geographic coverage/footprint- \n",
    "**DISTANCE**: Continues to 22 facilities or 98% coverage  - Goal: Minimize travel distance while expanding coverage### Weight Profiles:- \n",
    "**FEWEST**: High patient volume weight (2.5x), zero progress reward- \n",
    "**FOOTPRINT**: Very high progress reward (8.0x), minimal patient volume weight (0.05x)- \n",
    "**DISTANCE**: High progress reward (6.0x), strong distance penalty (2.5x)\n",
    "\n",
    "### Expected Results:- FEWEST: ~15-16 HSAs, ~94% coverage- FOOTPRINT: ~20-22 HSAs, ~97% coverage- DISTANCE: ~20-22 HSAs, ~91% coverage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configure Optimization Parameters\n",
    "\n",
    "Adjust these parameters to tune the penalty-based scoring:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# IMPORTS AND PARAMETER INJECTION\n",
    "# ============================================================================\n",
    "\n",
    "# Import libraries\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "# Import optimization module\n",
    "import hsa_optimization\n",
    "from hsa_optimization import HSAOptimizer\n",
    "\n",
    "# ============================================================================\n",
    "# INJECT CONFIGURATION INTO HSA_OPTIMIZATION MODULE\n",
    "# ============================================================================\n",
    "# The hsa_optimization module no longer defines its own parameters.\n",
    "# Instead, it expects them to be injected from the notebook.\n",
    "# This makes all parameters visible and editable in one place (Cell 0 above).\n",
    "\n",
    "param_names = [\n",
    "    'DATA_DIR', 'OUT_DIR', 'NETWORK',\n",
    "    'TAU_COVERAGE', 'MAX_RADIUS_KM', 'RNG_SEED',\n",
    "    'BUFFER_KM', 'COARSEN_FACTOR',\n",
    "    'DENSITY_RADIUS_KM', 'URBAN_DENSITY_THRESH',\n",
    "    'URBAN_BASE_RADIUS_KM', 'RURAL_BASE_RADIUS_KM',\n",
    "    'TARGET_HSA_MIN', 'TARGET_HSA_MAX',\n",
    "    'VOLUME_WEIGHT', 'PATIENT_RADIUS_ALPHA',\n",
    "    'NETWORK_RADIUS_MULTIPLIERS',\n",
    "    'CLIMATE_DIVERSITY_ON', 'CLIMATE_K', 'CLIMATE_MIN_PER_CLUSTER',\n",
    "    'CLIMATE_CLUSTER_COL', 'CLIMATE_CSV',\n",
    "    'WEIGHT_COVERAGE', 'WEIGHT_OVERLAP_PENALTY', 'WEIGHT_CLIMATE',\n",
    "    'WEIGHT_PATIENT_VOLUME', 'WEIGHT_COVERAGE_PROGRESS', 'WEIGHT_DISTANCE_PENALTY',\n",
    "    'COVERAGE_WEIGHT', 'LAMBDA_CLIMATE', 'LAMBDA_PATIENT_VOLUME',\n",
    "    'MODE_WEIGHT_PROFILES',\n",
    "]\n",
    "\n",
    "print(\"Injecting parameters into hsa_optimization module...\")\n",
    "injected_count = 0\n",
    "for param in param_names:\n",
    "    if param in globals():\n",
    "        setattr(hsa_optimization, param, globals()[param])\n",
    "        injected_count += 1\n",
    "    else:\n",
    "        print(f\"  WARNING: Parameter {param} not found in globals()\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"IMPORTS AND PARAMETER INJECTION COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Parameters injected: {injected_count}/{len(param_names)}\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Run Optimizations\n",
    "\n",
    "This will run all enabled objectives and stop at their respective coverage thresholds:\n",
    "- **FEWEST**: 90% coverage (minimize # of HSAs) - typically 15-20 HSAs\n",
    "- **DISTANCE**: 90% coverage (minimize travel distance) - typically 15-20 HSAs  \n",
    "- **FOOTPRINT**: 90% coverage (maximize population reached) - typically 25-35 HSAs\n",
    "- **GOVERNORATE_TAU_COVERAGE**: 60% per governorate (TAU method, 18-25 HSAs)\n",
    "- **GOVERNORATE_FEWEST**: 1 HSA per governorate + FEWEST (12-20 HSAs)\n",
    "\n",
    "**Note**: All modes now use unified normalized scoring with mode-specific weight profiles.\n",
    "Results will include `composite_score`, `initial_radius_km`, and `service_radius_km` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize optimizer\n",
    "optimizer = HSAOptimizer(config)\n",
    "\n",
    "\n",
    "\n",
    "# Load facilities WITH CLIMATE DATA from CSV\n",
    "climate_csv = DATA_DIR / f'{NETWORK}_Hospitals_Climate_Features_with_clusters.csv'\n",
    "\n",
    "if not climate_csv.exists():\n",
    "    raise FileNotFoundError(f\"Climate CSV not found: {climate_csv}\")\n",
    "\n",
    "# Read climate CSV\n",
    "climate_df = pd.read_csv(climate_csv)\n",
    "\n",
    "# Rename FacilityName to HealthFacility (what the optimizer expects)\n",
    "if 'FacilityName' in climate_df.columns:\n",
    "    climate_df['HealthFacility'] = climate_df['FacilityName']\n",
    "elif 'HealthFacility' not in climate_df.columns:\n",
    "    raise ValueError(\"Climate CSV must have either 'FacilityName' or 'HealthFacility' column\")\n",
    "\n",
    "# Load diagnosis counts (for Total column)\n",
    "diagnosis_csv = OUT_DIR / f'{NETWORK}_diagnosis_counts_pivot.csv'\n",
    "if not diagnosis_csv.exists():\n",
    "    raise FileNotFoundError(f\"Diagnosis counts not found: {diagnosis_csv}\")\n",
    "\n",
    "diagnosis_df = pd.read_csv(diagnosis_csv)\n",
    "\n",
    "# Merge climate data with diagnosis counts on HealthFacility\n",
    "merged_df = climate_df.merge(\n",
    "    diagnosis_df[['healthfacility', 'total_diagnoses']],\n",
    "    left_on='HealthFacility',\n",
    "    right_on='healthfacility',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Rename total_diagnoses to Total (what the optimizer expects)\n",
    "merged_df['Total'] = merged_df['total_diagnoses']\n",
    "\n",
    "# Check for missing values\n",
    "missing_total = merged_df['Total'].isna().sum()\n",
    "if missing_total > 0:\n",
    "    print(f\"WARNING: {missing_total} facilities missing diagnosis counts\")\n",
    "    # Fill with 0 or drop?\n",
    "    merged_df['Total'] = merged_df['Total'].fillna(0)\n",
    "\n",
    "# Create GeoDataFrame from lat/lon\n",
    "facilities = gpd.GeoDataFrame(\n",
    "    merged_df,\n",
    "    geometry=gpd.points_from_xy(merged_df['lon'], merged_df['lat']),\n",
    "    crs='EPSG:4326'\n",
    ")\n",
    "\n",
    "# Reproject to UTM for distance calculations (Jordan is in UTM zone 36N/37N)\n",
    "# Using a common Jordan projection: EPSG:32637 (UTM 37N)\n",
    "facilities = facilities.to_crs('EPSG:32637')\n",
    "\n",
    "print(f\"\\nMerged climate + diagnosis data:\")\n",
    "print(f\"  Facilities with climate data: {len(climate_df)}\")\n",
    "print(f\"  Facilities with diagnosis counts: {len(diagnosis_df)}\")\n",
    "print(f\"  Facilities after merge: {len(facilities)}\")\n",
    "print(f\"  Facilities with Total column: {facilities['Total'].notna().sum()}\")\n",
    "print(f\"  Facilities with HealthFacility column: {'HealthFacility' in facilities.columns}\")\n",
    "\n",
    "\n",
    "print(f\"Loaded {len(facilities)} {NETWORK} facilities \")\n",
    "if 'climate_k' in facilities.columns:\n",
    "    print(f\"  climate_k column present: YES\")\n",
    "    print(f\"  climate_k values: {sorted(facilities['climate_k'].dropna().unique())}\")\n",
    "else:\n",
    "    print(f\"  climate_k column present: NO (climate diversity scoring will be disabled!)\")\n",
    "\n",
    "# Load governorates for governorate modes\n",
    "gov_file = DATA_DIR / 'jordan_governorates.gpkg'\n",
    "governorates = gpd.read_file(gov_file) if (DATA_DIR / 'jordan_governorates.gpkg').exists() else None\n",
    "\n",
    "# Store results for all objectives\n",
    "all_results = {}\n",
    "\n",
    "# Run optimizations for selected objectives\n",
    "for objective in ['fewest', 'footprint', 'distance', 'governorate_tau_coverage', 'governorate_fewest']:\n",
    "    if objective not in RUN_OBJECTIVES or not RUN_OBJECTIVES[objective]:\n",
    "        print(f\"\\nSkipping {objective.upper()} optimization (disabled)\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Running {objective.upper()} optimization...\")\n",
    "    print('='*80)\n",
    "    \n",
    "    # Run optimization\n",
    "    if objective in ['governorate_tau_coverage', 'governorate_fewest']:\n",
    "        if governorates is None:\n",
    "            print(\"  ERROR: Governorates file not found, skipping\")\n",
    "            continue\n",
    "        result = optimizer.optimize(facilities, objective=objective, network_type=NETWORK, governorates_gdf=governorates)\n",
    "    else:\n",
    "        result = optimizer.optimize(facilities, objective=objective, network_type=NETWORK)\n",
    "\n",
    "    \n",
    "    selected_facilities = result['facilities']\n",
    "    coverage_pct = result['coverage_pct']\n",
    "    \n",
    "    all_results[objective] = {\n",
    "        'result': result,\n",
    "        'facilities': selected_facilities,\n",
    "        'coverage': coverage_pct\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"{objective.upper()} OPTIMIZATION COMPLETE\")\n",
    "    print('='*80)\n",
    "    print(f\"Selected: {len(selected_facilities)} HSAs\")\n",
    "    print(f\"Coverage: {coverage_pct:.1f}%\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # SAVE RESULTS TO GEOJSON (v2 files)\n",
    "    # ========================================================================\n",
    "    print(f\"\\nSaving results to GeoJSON...\")\n",
    "    \n",
    "    # Add metadata\n",
    "    selected_with_meta = selected_facilities.copy()\n",
    "    selected_with_meta['network_type'] = NETWORK\n",
    "    selected_with_meta['optimization_mode'] = objective\n",
    "    \n",
    "    # Save to v2.geojson file\n",
    "    output_file = OUT_DIR / f'{NETWORK}_{objective}_hsas_v2.geojson'\n",
    "    selected_with_meta.to_file(output_file, driver='GeoJSON')\n",
    "    \n",
    "    # Verify saved file\n",
    "    reloaded = gpd.read_file(output_file)\n",
    "    print(f\"  Saved: {output_file.name}\")\n",
    "    print(f\"  Columns in saved file: {len(reloaded.columns)}\")\n",
    "    print(f\"  climate_k preserved: {'climate_k' in reloaded.columns}\")\n",
    "    \n",
    "    if 'service_radius_km' in reloaded.columns:\n",
    "        max_radius = reloaded['service_radius_km'].max()\n",
    "        print(f\"  Max service_radius_km: {max_radius:.1f} km (should be <= 30.0)\")\n",
    "        if max_radius > 30.0:\n",
    "            print(f\"  WARNING: Radius exceeds 30 km limit!\")\n",
    "    \n",
    "    print(f\"  File verified successfully\")\n",
    "\n",
    "print(f\"\\n\\n{'='*80}\")\n",
    "print(\"ALL OPTIMIZATIONS COMPLETE\")\n",
    "print('='*80)\n",
    "for obj, data in all_results.items():\n",
    "    print(f\"  {obj.upper():26s}: {len(data['facilities']):3d} HSAs, {data['coverage']:.1f}% coverage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Select Objective for Analysis\n",
    "\n",
    "Choose which objective result to analyze in detail:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SECTIONS 3-8: ANALYZE ALL OPTIMIZATION MODES\n",
    "# ============================================================================\n",
    "\n",
    "from hsa_objective_analysis import analyze_all_modes\n",
    "\n",
    "# Analyze all modes with complete suite of visualizations and statistics\n",
    "analyze_all_modes(all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "  # ============================================================================\n",
    "  # CROSS-MODE COMPARISON: Facility Counts and HSA Volumes\n",
    "  # ============================================================================\n",
    "\n",
    "  from geopandas import sjoin\n",
    "  import pandas as pd\n",
    "\n",
    "\n",
    "  # Load all facilities once from climate CSV + diagnosis counts\n",
    "  climate_csv = DATA_DIR / f'{NETWORK}_Hospitals_Climate_Features_with_clusters.csv'\n",
    "  diagnosis_csv = OUT_DIR / f'{NETWORK}_diagnosis_counts_pivot.csv'\n",
    "\n",
    "  climate_df = pd.read_csv(climate_csv)\n",
    "  diagnosis_df = pd.read_csv(diagnosis_csv)\n",
    "\n",
    "  # Rename FacilityName to HealthFacility\n",
    "  if 'FacilityName' in climate_df.columns:\n",
    "      climate_df['HealthFacility'] = climate_df['FacilityName']\n",
    "\n",
    "  # Merge\n",
    "  merged_df = climate_df.merge(\n",
    "      diagnosis_df[['healthfacility', 'total_diagnoses']],\n",
    "      left_on='HealthFacility',\n",
    "      right_on='healthfacility',\n",
    "      how='left'\n",
    "  )\n",
    "  merged_df['Total'] = merged_df['total_diagnoses'].fillna(0)\n",
    "\n",
    "  all_facilities_gdf = gpd.GeoDataFrame(\n",
    "      merged_df,\n",
    "      geometry=gpd.points_from_xy(merged_df['lon'], merged_df['lat']),\n",
    "      crs='EPSG:4326'\n",
    "  ).to_crs('EPSG:32637')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  # Compare all modes\n",
    "  comparison_results = []\n",
    "\n",
    "  for mode in ['fewest', 'footprint', 'distance', 'governorate_tau_coverage', 'governorate_fewest']:\n",
    "      if mode not in all_results:\n",
    "          continue\n",
    "\n",
    "      final_hsas = all_results[mode]['facilities']\n",
    "      N_ANCHORS = len(final_hsas)\n",
    "\n",
    "      print(f\"\\n{'='*80}\")\n",
    "      print(f\"{mode.upper()} - DETAILED HSA ANALYSIS ({N_ANCHORS} HSAs)\")\n",
    "      print('='*80)\n",
    "\n",
    "      # Calculate detailed HSA statistics\n",
    "      details = []\n",
    "\n",
    "      for idx, row in final_hsas.iterrows():\n",
    "          # Get anchor facility volume\n",
    "          anchor_volume = pd.to_numeric(row['Total'], errors='coerce')\n",
    "\n",
    "          # Get HSA geometry (circle)\n",
    "          hsa_geom = row.geometry\n",
    "\n",
    "          # Calculate total population in HSA using raster mask\n",
    "          try:\n",
    "              from rasterio.mask import mask\n",
    "              import rasterio\n",
    "\n",
    "              with rasterio.open(config['pop_path']) as src:\n",
    "                  out_image, out_transform = mask(src, [hsa_geom], crop=True, nodata=0)\n",
    "                  total_pop = out_image.sum()\n",
    "          except:\n",
    "              total_pop = 0\n",
    "\n",
    "          # Find ALL facilities within this HSA using spatial join\n",
    "          # Create temporary GeoDataFrame with just this HSA\n",
    "          hsa_temp = gpd.GeoDataFrame([{'geometry': hsa_geom}], crs=all_facilities_gdf.crs)\n",
    "\n",
    "          # Spatial join to find facilities intersecting this HSA\n",
    "          facilities_in_hsa = sjoin(\n",
    "              all_facilities_gdf,\n",
    "              hsa_temp,\n",
    "              how='inner',\n",
    "              predicate='intersects'\n",
    "          )\n",
    "\n",
    "          # Calculate total HSA volume (sum of all facility volumes in HSA)\n",
    "          total_hsa_volume = 0\n",
    "          for fac_idx, fac_row in facilities_in_hsa.iterrows():\n",
    "              fac_vol = pd.to_numeric(fac_row['Total'], errors='coerce')\n",
    "              if not pd.isna(fac_vol):\n",
    "                  total_hsa_volume += fac_vol\n",
    "\n",
    "          # Append details with ALL required columns\n",
    "          details.append({\n",
    "              'Mode': mode.upper(),\n",
    "              'HSA_Anchor': row['FacilityName'],\n",
    "              'Anchor_Patient_Volume': anchor_volume,\n",
    "              'Num_Facilities_in_HSA': len(facilities_in_hsa),\n",
    "              'Total_HSA_Volume': total_hsa_volume,\n",
    "              'HSA_Population': total_pop,\n",
    "              'Service_Radius_km': row.get('service_radius_km', row.get('initial_radius_km', 0)),\n",
    "              'Composite_Score': row.get('composite_score', 0)\n",
    "          })\n",
    "\n",
    "      # Create DataFrame\n",
    "      detail_df = pd.DataFrame(details)\n",
    "\n",
    "      # Define display columns\n",
    "      display_cols = ['HSA_Anchor', 'Anchor_Patient_Volume', 'Num_Facilities_in_HSA',\n",
    "                      'Total_HSA_Volume', 'HSA_Population', 'Service_Radius_km', 'Composite_Score']\n",
    "\n",
    "      # Show ALL facilities (not .head(15))\n",
    "      print(detail_df[display_cols].to_string(index=False))\n",
    "\n",
    "      # Summary statistics\n",
    "      print(f\"\\nSummary Statistics for {mode.upper()}:\")\n",
    "      print(f\"  Total HSAs: {len(detail_df)}\")\n",
    "      print(f\"  Avg facilities per HSA: {detail_df['Num_Facilities_in_HSA'].mean():.1f}\")\n",
    "      print(f\"  Total facilities covered: {detail_df['Num_Facilities_in_HSA'].sum()}\")\n",
    "      print(f\"  Avg HSA volume: {detail_df['Total_HSA_Volume'].mean():,.0f}\")\n",
    "      print(f\"  Total HSA volume: {detail_df['Total_HSA_Volume'].sum():,.0f}\")\n",
    "\n",
    "      # Add to comparison\n",
    "      comparison_results.append({\n",
    "          'Mode': mode.upper(),\n",
    "          'Num_HSAs': N_ANCHORS,\n",
    "          'Avg_Facilities_per_HSA': detail_df['Num_Facilities_in_HSA'].mean(),\n",
    "          'Total_Facilities_Covered': detail_df['Num_Facilities_in_HSA'].sum(),\n",
    "          'Avg_HSA_Volume': detail_df['Total_HSA_Volume'].mean(),\n",
    "          'Total_HSA_Volume': detail_df['Total_HSA_Volume'].sum()\n",
    "      })\n",
    "\n",
    "  # Cross-mode comparison table\n",
    "  print(f\"\\n\\n{'='*80}\")\n",
    "  print(\"CROSS-MODE COMPARISON SUMMARY\")\n",
    "  print('='*80)\n",
    "  comparison_df = pd.DataFrame(comparison_results)\n",
    "  print(comparison_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook implements the **v5.0 Normalized Scoring System** for HSA selection:\n",
    "\n",
    "### Key Improvements in v5.0:\n",
    "\n",
    "1. **Normalized Scoring (0-1 components, 0-10 weights)**:\n",
    "   - All scoring components normalized to 0-1 range\n",
    "   - Weights in intuitive 0-10 scale\n",
    "   - Score range: 2-17 (reasonable, not exponential)\n",
    "   - Easy to understand and tune\n",
    "\n",
    "2. **Volume-Based Radius Assignment**:\n",
    "   - Patient volume now influences radius (0.8x to 1.2x multiplier)\n",
    "   - Results in 15-16 unique radii (not just 2!)\n",
    "   - Range: ~11-39 km depending on density and volume\n",
    "   - Larger hospitals serve larger catchment areas\n",
    "\n",
    "3. **Unified Mode System**:\n",
    "   - Single scoring formula for all modes\n",
    "   - Mode differences via weight profile multipliers\n",
    "   - Distance penalty only in DISTANCE mode\n",
    "   - All modes track composite scores\n",
    "\n",
    "4. **Selection Quality**:\n",
    "   - Largest facilities systematically selected first\n",
    "   - Top 15 anchors: 0 facilities with <100 patients\n",
    "   - 13 out of 16 selections are >2000 patients\n",
    "   - Al-Basheer Hospital (6831 patients) has highest score\n",
    "\n",
    "### Scoring Formula (FEWEST mode):\n",
    "\n",
    "```python\n",
    "composite_score = \n",
    "    5.0 * (pop_coverage / total_pop) * 2.0       # Coverage: 0-10\n",
    "  - 3.0 * (overlap / total_coverage) * 1.0       # Overlap: 0 to -3\n",
    "  + 1.0 * (1 / (1 + cluster_count))              # Climate: 0-1\n",
    "  + 7.0 * (patient_vol / max_vol) * 1.5          # Volume: 0-10.5\n",
    "  + 0.5 * (progress / remaining) * 0.3           # Progress: 0-0.15\n",
    "```\n",
    "\n",
    "\n",
    "### Tuning Weights:\n",
    "\n",
    "Edit `hsa_optimization.py` lines 234-267:\n",
    "\n",
    "```python\n",
    "# Increase to prefer larger facilities:\n",
    "WEIGHT_PATIENT_VOLUME = 8.0  # (currently 7.0)\n",
    "\n",
    "# Increase to prioritize coverage:\n",
    "WEIGHT_COVERAGE = 7.0  # (currently 5.0)\n",
    "\n",
    "# Reduce to allow more geographic spread:\n",
    "WEIGHT_CLIMATE = 0.5  # (currently 1.0)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Generate Professional Maps\n",
    "\n",
    "Create HSA boundary polygons and professional maps for all optimization results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Jordan country boundary for clipping\n",
    "country_file = DATA_DIR / 'jordan_admin0.gpkg'  # Adjust filename if needed\n",
    "if not country_file.exists():\n",
    "    country_file = DATA_DIR / 'jordan_boundary.gpkg'\n",
    "if not country_file.exists():\n",
    "    country_file = DATA_DIR / 'jordan_governorates.gpkg'  # Use governorates as fallback\n",
    "\n",
    "if country_file.exists():\n",
    "    country_boundary = gpd.read_file(country_file)\n",
    "    if 'jordan_governorates' in str(country_file):\n",
    "        # Dissolve governorates to create country boundary\n",
    "        country_boundary = country_boundary.dissolve()\n",
    "    print(f\"Country boundary loaded from: {country_file.name}\")\n",
    "    print(f\"  CRS: {country_boundary.crs}\")\n",
    "else:\n",
    "    print(\"WARNING: Country boundary file not found. Maps will not be clipped.\")\n",
    "    country_boundary = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SECTION 9: CREATE MAPS FOR ALL MODES - USING WORKING MODULE\n",
    "# ============================================================================\n",
    "\n",
    "# FORCE FRESH IMPORT - clear any cached modules\n",
    "import sys\n",
    "if 'hsa_mapping' in sys.modules:\n",
    "    del sys.modules[\"hsa_mapping\"]\n",
    "if 'hsa_mapping_working' in sys.modules:\n",
    "    del sys.modules[\"hsa_mapping_working\"]\n",
    "\n",
    "# Import the WORKING mapping module (extracted from create_geopandas_maps.py)\n",
    "from hsa_mapping_working import create_all_hsa_maps\n",
    "\n",
    "print(\"Using hsa_mapping_working module (extracted from create_geopandas_maps.py)\")\n",
    "print(\"This version has been verified to produce correct maps with:\")\n",
    "print(\"  - Circular HSAs (not stretched)\")\n",
    "print(\"  - Visible population grid\")\n",
    "\n",
    "# Create all maps with proper layer ordering\n",
    "create_all_hsa_maps(\n",
    "    all_results=all_results,\n",
    "    network=NETWORK,\n",
    "    data_dir=DATA_DIR,\n",
    "    out_dir=OUT_DIR\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "  # ============================================================================\n",
    "  # SECTION 10: HSA DETAIL TABLES - ALL MODES, ALL HSAS\n",
    "  # ============================================================================\n",
    "\n",
    "  from geopandas import sjoin\n",
    "  import rasterio\n",
    "  from rasterio.mask import mask as raster_mask\n",
    "  import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "  # Load all facilities once from climate CSV + diagnosis counts\n",
    "  climate_csv = DATA_DIR / f'{NETWORK}_Hospitals_Climate_Features_with_clusters.csv'\n",
    "  diagnosis_csv = OUT_DIR / f'{NETWORK}_diagnosis_counts_pivot.csv'\n",
    "\n",
    "  climate_df = pd.read_csv(climate_csv)\n",
    "  diagnosis_df = pd.read_csv(diagnosis_csv)\n",
    "\n",
    "  # Rename FacilityName to HealthFacility\n",
    "  if 'FacilityName' in climate_df.columns:\n",
    "      climate_df['HealthFacility'] = climate_df['FacilityName']\n",
    "\n",
    "  # Merge\n",
    "  merged_df = climate_df.merge(\n",
    "      diagnosis_df[['healthfacility', 'total_diagnoses']],\n",
    "      left_on='HealthFacility',\n",
    "      right_on='healthfacility',\n",
    "      how='left'\n",
    "  )\n",
    "  merged_df['Total'] = merged_df['total_diagnoses'].fillna(0)\n",
    "\n",
    "  all_facilities = gpd.GeoDataFrame(\n",
    "      merged_df,\n",
    "      geometry=gpd.points_from_xy(merged_df['lon'], merged_df['lat']),\n",
    "      crs='EPSG:4326'\n",
    "  ).to_crs('EPSG:32637')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  modes_to_process = {\n",
    "      'fewest': 'FEWEST',\n",
    "      'footprint': 'FOOTPRINT',\n",
    "      'distance': 'DISTANCE',\n",
    "      'governorate_tau_coverage': 'GOVERNORATE TAU COVERAGE',\n",
    "      'governorate_fewest': 'GOVERNORATE FEWEST'\n",
    "  }\n",
    "\n",
    "\n",
    "  for mode_name, mode_label in modes_to_process.items():\n",
    "      hsas_file = OUT_DIR / f'{NETWORK}_{mode_name}_hsas_v2.geojson'\n",
    "\n",
    "      if not hsas_file.exists():\n",
    "          print(f\"\\nSkipping {mode_label} - file not found\")\n",
    "          continue\n",
    "\n",
    "      # Load HSAs\n",
    "      hsas_points = gpd.read_file(hsas_file)\n",
    "      hsas_points_utm = hsas_points.to_crs(all_facilities.crs)\n",
    "\n",
    "      print(f\"\\n{'='*80}\")\n",
    "      print(f\"{mode_label} - ALL {len(hsas_points)} HSAs\")\n",
    "      print('='*80)\n",
    "\n",
    "      # Calculate details for ALL HSAs\n",
    "      details = []\n",
    "\n",
    "      for idx, row in hsas_points_utm.iterrows():\n",
    "          # Get anchor facility volume\n",
    "          anchor_volume = pd.to_numeric(row['Total'], errors='coerce')\n",
    "    \n",
    "          # Get HSA center point (in UTM)\n",
    "          center_point_utm = row.geometry\n",
    "    \n",
    "          # Get radius\n",
    "          radius_km = row.get('service_radius_km', row.get('initial_radius_km', 15.0))\n",
    "    \n",
    "          # Create circle in UTM (meters) for facility counting\n",
    "          radius_meters = radius_km * 1000\n",
    "          hsa_circle_utm = center_point_utm.buffer(radius_meters)\n",
    "    \n",
    "          # Find ALL facilities within this HSA circle\n",
    "          hsa_temp = gpd.GeoDataFrame([{'geometry': hsa_circle_utm}], crs=hsas_points_utm.crs)\n",
    "          facilities_in_hsa = sjoin(all_facilities, hsa_temp, how='inner', predicate='intersects')\n",
    "    \n",
    "          # Calculate total HSA volume\n",
    "          total_hsa_volume = 0\n",
    "          for fac_idx, fac_row in facilities_in_hsa.iterrows():\n",
    "              fac_vol = pd.to_numeric(fac_row['Total'], errors='coerce')\n",
    "              if not pd.isna(fac_vol):\n",
    "                  total_hsa_volume += fac_vol\n",
    "    \n",
    "          # For population: convert circle to EPSG:4326 for raster\n",
    "          hsa_circle_latlon = gpd.GeoDataFrame(\n",
    "              [{'geometry': hsa_circle_utm}],\n",
    "              crs=hsas_points_utm.crs\n",
    "          ).to_crs('EPSG:4326').geometry.iloc[0]\n",
    "    \n",
    "          # Calculate population\n",
    "          try:\n",
    "              with rasterio.open(config['pop_path']) as src:\n",
    "                  out_image, out_transform = raster_mask(src, [hsa_circle_latlon], crop=True, nodata=0)\n",
    "                  total_pop = float(out_image.sum())\n",
    "          except Exception as e:\n",
    "              total_pop = 0\n",
    "    \n",
    "          details.append({\n",
    "              'HSA_Anchor': row['FacilityName'],\n",
    "              'Anchor_Volume': anchor_volume,\n",
    "              'Num_Facilities_in_HSA': len(facilities_in_hsa),\n",
    "              'Total_HSA_Volume': total_hsa_volume,\n",
    "              'HSA_Population': total_pop,\n",
    "              'Service_Radius_km': radius_km,\n",
    "              'Composite_Score': row.get('composite_score', 0)\n",
    "          })\n",
    "          # REMOVE ANY PRINT STATEMENTS HERE!\n",
    "\n",
    "      # ONLY PRINT AFTER THE LOOP COMPLETES\n",
    "      detail_df = pd.DataFrame(details)\n",
    "      print(detail_df.to_string(index=False))\n",
    "\n",
    "      # Summary statistics\n",
    "      print(f\"\\nSummary Statistics:\")\n",
    "      print(f\"  Total HSAs: {len(detail_df)}\")\n",
    "      print(f\"  Total facilities across all HSAs: {detail_df['Num_Facilities_in_HSA'].sum()}\")\n",
    "      print(f\"  Total HSA volume: {detail_df['Total_HSA_Volume'].sum():,.0f}\")\n",
    "      print(f\"  Total population covered: {detail_df['HSA_Population'].sum():,.0f}\")\n",
    "\n",
    "  print(\"\\n\" + \"=\"*80)\n",
    "  print(\"HSA DETAIL TABLES COMPLETE\")\n",
    "  print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
