{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "djtjvgBCSDZk"
   },
   "source": [
    "# Climate Feature Extraction for Hospital Service Areas\n",
    "\n",
    "**Purpose**: Extract comprehensive climate features at facility locations from multiple satellite/reanalysis datasets\n",
    "\n",
    "**Study Period**: January 2019 - January 2024\n",
    "\n",
    "**Datasets**:\n",
    "- CHIRPS: Daily precipitation\n",
    "- ERA5-Land: Temperature, humidity, wind\n",
    "- TerraClimate: Water balance (ET, PET, VPD, runoff)\n",
    "- SRTM: Elevation\n",
    "\n",
    "**Output**: Per-facility climate summary statistics suitable for k-means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CVAO-RzmSDZo"
   },
   "outputs": [],
   "source": [
    "#@title Install and import libraries\n",
    "!pip -q install earthengine-api geemap geopandas shapely pandas numpy scikit-learn matplotlib\n",
    "\n",
    "import ee\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from google.colab import files\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "print(\"Libraries installed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qwHL2IITSDZp"
   },
   "outputs": [],
   "source": [
    "#@title Authenticate and initialize Earth Engine\n",
    "try:\n",
    "    ee.Initialize()\n",
    "    print('✓ Earth Engine initialized')\n",
    "except Exception:\n",
    "    ee.Authenticate()\n",
    "    ee.Initialize(project='ee-izaslavsky')\n",
    "    print('✓ Earth Engine authenticated and initialized')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rsSM57EwSDZp"
   },
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S6PccelBSDZp"
   },
   "outputs": [],
   "source": [
    "#@title Configuration parameters\n",
    "\n",
    "# Study period\n",
    "START_DATE = '2019-01-01'  #@param {type:\"string\"}\n",
    "END_DATE = '2024-01-31'    #@param {type:\"string\"}\n",
    "\n",
    "# Spatial parameters\n",
    "BUFFER_METERS = 2500  #@param {type:\"number\"}\n",
    "SCALE_METERS = 5000   #@param {type:\"number\"}\n",
    "\n",
    "# Output settings\n",
    "OUTPUT_PREFIX = 'Hospitals_Climate_Features'  #@param {type:\"string\"}\n",
    "\n",
    "print(f\"Study period: {START_DATE} to {END_DATE}\")\n",
    "print(f\"Buffer radius: {BUFFER_METERS}m\")\n",
    "print(f\"Spatial scale: {SCALE_METERS}m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B0rS6InGSDZq"
   },
   "source": [
    "## Load Facility Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1m6ejMRuSDZq"
   },
   "outputs": [],
   "source": [
    "#@title Upload facility file\n",
    "\n",
    "USE_DEMO = False  #@param {type:\"boolean\"}\n",
    "\n",
    "if USE_DEMO:\n",
    "    # Demo data for Jordan (approximate locations)\n",
    "    df_demo = pd.DataFrame({\n",
    "        'FacilityName': ['Amman_Hospital', 'Zarqa_Hospital', 'Irbid_Hospital', 'Aqaba_Hospital', 'Mafraq_Hospital'],\n",
    "        'Category': ['NCD', 'NCD', 'INF', 'NCD', 'INF'],\n",
    "        'lat': [31.95, 32.07, 32.55, 29.53, 32.34],\n",
    "        'lon': [35.93, 36.09, 35.85, 35.01, 36.21]\n",
    "    })\n",
    "    gdf = gpd.GeoDataFrame(\n",
    "        df_demo,\n",
    "        geometry=gpd.points_from_xy(df_demo['lon'], df_demo['lat']),\n",
    "        crs='EPSG:4326'\n",
    "    )\n",
    "    print(f\"✓ Using demo data: {len(gdf)} facilities\")\n",
    "else:\n",
    "    print('Upload your facility file (CSV/GeoJSON/Shapefile/GPKG):')\n",
    "    print('It will look like INF_facility_coordinates.csv:')\n",
    "    uploaded = files.upload()\n",
    "    fname = next(iter(uploaded.keys()))\n",
    "    ext = fname.lower().split('.')[-1]\n",
    "\n",
    "    if ext == 'csv':\n",
    "        df = pd.read_csv(fname)\n",
    "        # Find coordinate columns\n",
    "        cols_lower = {c.lower(): c for c in df.columns}\n",
    "        lat_col = cols_lower.get('lat') or cols_lower.get('latitude') or cols_lower.get('y')\n",
    "        lon_col = cols_lower.get('lon') or cols_lower.get('lng') or cols_lower.get('longitude') or cols_lower.get('x')\n",
    "        id_col = cols_lower.get('id') or cols_lower.get('healthfacility') or cols_lower.get('name') or df.columns[0]\n",
    "\n",
    "        if not (lat_col and lon_col):\n",
    "            raise ValueError(f\"Could not find lat/lon columns. Available: {df.columns.tolist()}\")\n",
    "\n",
    "        gdf = gpd.GeoDataFrame(\n",
    "            df.rename(columns={id_col: 'FacilityName'}),\n",
    "            geometry=gpd.points_from_xy(df[lon_col], df[lat_col]),\n",
    "            crs='EPSG:4326'\n",
    "        )\n",
    "    else:\n",
    "        gdf = gpd.read_file(fname)\n",
    "        # Ensure FacilityName column exists\n",
    "        if 'FacilityName' not in gdf.columns:\n",
    "            for candidate in ['id', 'healthfacility', 'name', 'Name', 'Hospital']:\n",
    "                if candidate in gdf.columns:\n",
    "                    gdf = gdf.rename(columns={candidate: 'FacilityName'})\n",
    "                    break\n",
    "            else:\n",
    "                gdf['FacilityName'] = [f'facility_{i}' for i in range(len(gdf))]\n",
    "\n",
    "    print(f\"✓ Loaded {len(gdf)} facilities\")\n",
    "\n",
    "# Ensure WGS84\n",
    "if gdf.crs is None:\n",
    "    gdf = gdf.set_crs('EPSG:4326')\n",
    "else:\n",
    "    gdf = gdf.to_crs('EPSG:4326')\n",
    "\n",
    "print(f\"\\nColumns: {gdf.columns.tolist()}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(gdf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8XbR4HJ2SDZr"
   },
   "outputs": [],
   "source": [
    "#@title Convert to Earth Engine FeatureCollection\n",
    "\n",
    "def gdf_to_ee_fc(gdf_input, buffer_m=0):\n",
    "    \"\"\"Convert GeoDataFrame to EE FeatureCollection with optional buffer\"\"\"\n",
    "    features = []\n",
    "    for idx, row in gdf_input.iterrows():\n",
    "        geom = row.geometry\n",
    "        if geom is None or geom.is_empty:\n",
    "            continue\n",
    "\n",
    "        # Create EE geometry\n",
    "        if geom.geom_type == 'Point':\n",
    "            ee_geom = ee.Geometry.Point([geom.x, geom.y])\n",
    "        else:\n",
    "            ee_geom = ee.Geometry(geom.__geo_interface__)\n",
    "\n",
    "        # Apply buffer if specified\n",
    "        if buffer_m > 0:\n",
    "            ee_geom = ee_geom.buffer(buffer_m)\n",
    "\n",
    "        # Add properties (convert complex types to strings)\n",
    "        props = {\n",
    "            'FacilityName': str(row.get('FacilityName', f'facility_{idx}')),\n",
    "            'lat': float(geom.y) if geom.geom_type == 'Point' else None,\n",
    "            'lon': float(geom.x) if geom.geom_type == 'Point' else None,\n",
    "        }\n",
    "\n",
    "        # Add Category if present\n",
    "        if 'Category' in row:\n",
    "            props['Category'] = str(row['Category'])\n",
    "\n",
    "        features.append(ee.Feature(ee_geom, props))\n",
    "\n",
    "    return ee.FeatureCollection(features)\n",
    "\n",
    "fc_facilities = gdf_to_ee_fc(gdf, buffer_m=BUFFER_METERS)\n",
    "n_facilities = fc_facilities.size().getInfo()\n",
    "print(f\"✓ Created FeatureCollection with {n_facilities} facilities\")\n",
    "print(f\"  Buffer: {BUFFER_METERS}m around each point\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IoDai4t9SDZr"
   },
   "source": [
    "## Define Climate Feature Extraction Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6ZDLo76nSDZs"
   },
   "outputs": [],
   "source": [
    "#@title CHIRPS Precipitation Features\n",
    "\n",
    "def extract_chirps_features(fc, start, end, scale):\n",
    "    \"\"\"\n",
    "    Extract precipitation statistics from CHIRPS daily dataset\n",
    "    Returns: P_mean, P_total, wetday_frac, heavy_days, P95_threshold\n",
    "    \"\"\"\n",
    "    chirps = ee.ImageCollection('UCSB-CHG/CHIRPS/DAILY').filterDate(start, end)\n",
    "\n",
    "    # Mean precipitation\n",
    "    precip_mean = chirps.select('precipitation').mean()\n",
    "\n",
    "    # Total precipitation\n",
    "    precip_total = chirps.select('precipitation').sum()\n",
    "\n",
    "    # Wet day fraction (>1mm)\n",
    "    wet_days = chirps.select('precipitation').map(lambda img: img.gt(1.0))\n",
    "    wet_day_frac = wet_days.mean()\n",
    "\n",
    "    # Heavy precipitation days (>95th percentile)\n",
    "    # First calculate 95th percentile\n",
    "    p95 = chirps.select('precipitation').reduce(ee.Reducer.percentile([95]))\n",
    "\n",
    "    # Count days exceeding p95 (expressed as days per year)\n",
    "    n_years = ee.Date(end).difference(ee.Date(start), 'year')\n",
    "    heavy_days = chirps.select('precipitation').map(\n",
    "        lambda img: img.gte(p95)\n",
    "    ).sum().divide(n_years)\n",
    "\n",
    "    # Combine into single image\n",
    "    combined = ee.Image.cat([\n",
    "        precip_mean.rename('P_mean_mm'),\n",
    "        precip_total.rename('P_total_mm'),\n",
    "        wet_day_frac.rename('wetday_frac'),\n",
    "        heavy_days.rename('heavy_days_per_year'),\n",
    "        p95.rename('P95_threshold_mm')\n",
    "    ])\n",
    "\n",
    "    # Extract to facilities\n",
    "    def reduce_feature(feat):\n",
    "        reduced = combined.reduceRegion(\n",
    "            reducer=ee.Reducer.mean(),\n",
    "            geometry=feat.geometry(),\n",
    "            scale=scale,\n",
    "            maxPixels=1e9\n",
    "        )\n",
    "        return feat.set(reduced)\n",
    "\n",
    "    return fc.map(reduce_feature)\n",
    "\n",
    "print(\"✓ CHIRPS extraction function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6iwXDBhNSDZs"
   },
   "outputs": [],
   "source": [
    "#@title ERA5-Land Temperature & Meteorological Features\n",
    "\n",
    "def extract_era5_features(fc, start, end, scale):\n",
    "    \"\"\"\n",
    "    Extract temperature and meteorological variables from ERA5-Land\n",
    "    Returns: T_mean, T_min, T_max, DTR, T_hot_days, dewpoint, wind_speed\n",
    "    \"\"\"\n",
    "    era5 = ee.ImageCollection('ECMWF/ERA5_LAND/DAILY_AGGR').filterDate(start, end)\n",
    "\n",
    "    # Temperature (convert from K to C)\n",
    "    temp_mean = era5.select('temperature_2m').mean().subtract(273.15)\n",
    "    temp_min = era5.select('temperature_2m_min').mean().subtract(273.15)\n",
    "    temp_max = era5.select('temperature_2m_max').mean().subtract(273.15)\n",
    "\n",
    "    # Diurnal Temperature Range\n",
    "    dtr = era5.map(lambda img:\n",
    "        img.select('temperature_2m_max').subtract(img.select('temperature_2m_min'))\n",
    "    ).mean()\n",
    "\n",
    "    # Hot days (>35°C)\n",
    "    n_years = ee.Date(end).difference(ee.Date(start), 'year')\n",
    "    hot_days = era5.select('temperature_2m_max').map(\n",
    "        lambda img: img.subtract(273.15).gt(35)\n",
    "    ).sum().divide(n_years)\n",
    "\n",
    "    # Dewpoint temperature (proxy for humidity)\n",
    "    dewpoint_mean = era5.select('dewpoint_temperature_2m').mean().subtract(273.15)\n",
    "\n",
    "    # Wind speed (u and v components)\n",
    "    u_wind = era5.select('u_component_of_wind_10m')\n",
    "    v_wind = era5.select('v_component_of_wind_10m')\n",
    "    wind_speed = u_wind.map(lambda img:\n",
    "        img.pow(2).add(v_wind.filterDate(img.date(), img.date().advance(1, 'day')).first().pow(2)).sqrt()\n",
    "    ).mean()\n",
    "\n",
    "    # Combine\n",
    "    combined = ee.Image.cat([\n",
    "        temp_mean.rename('T_mean_C'),\n",
    "        temp_min.rename('T_min_C'),\n",
    "        temp_max.rename('T_max_C'),\n",
    "        dtr.rename('DTR_C'),\n",
    "        hot_days.rename('hot_days_per_year'),\n",
    "        dewpoint_mean.rename('dewpoint_C'),\n",
    "        wind_speed.rename('wind_speed_ms')\n",
    "    ])\n",
    "\n",
    "    # Extract to facilities\n",
    "    def reduce_feature(feat):\n",
    "        reduced = combined.reduceRegion(\n",
    "            reducer=ee.Reducer.mean(),\n",
    "            geometry=feat.geometry(),\n",
    "            scale=scale,\n",
    "            maxPixels=1e9\n",
    "        )\n",
    "        return feat.set(reduced)\n",
    "\n",
    "    return fc.map(reduce_feature)\n",
    "\n",
    "print(\"✓ ERA5-Land extraction function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w22XPEzoSDZt"
   },
   "outputs": [],
   "source": [
    "#@title TerraClimate Water Balance Features\n",
    "\n",
    "def extract_terraclimate_features(fc, start, end, scale):\n",
    "    \"\"\"\n",
    "    Extract water balance variables from TerraClimate\n",
    "    Returns: PET, AET, deficit, runoff, soil_moisture, VPD\n",
    "    \"\"\"\n",
    "    # TerraClimate is monthly, so we'll get monthly means\n",
    "    terra = ee.ImageCollection('IDAHO_EPSCOR/TERRACLIMATE').filterDate(start, end)\n",
    "\n",
    "    # Potential Evapotranspiration (mm)\n",
    "    pet_mean = terra.select('pet').mean()\n",
    "\n",
    "    # Actual Evapotranspiration (mm)\n",
    "    aet_mean = terra.select('aet').mean()\n",
    "\n",
    "    # Climate Water Deficit (PET - AET)\n",
    "    deficit_mean = terra.select('def').mean()\n",
    "\n",
    "    # Runoff (mm)\n",
    "    runoff_mean = terra.select('ro').mean()\n",
    "\n",
    "    # Soil moisture (mm)\n",
    "    soil_mean = terra.select('soil').mean()\n",
    "\n",
    "    # Vapor Pressure Deficit (kPa)\n",
    "    vpd_mean = terra.select('vpd').mean().divide(10)  # Convert to kPa\n",
    "\n",
    "    # Combine\n",
    "    combined = ee.Image.cat([\n",
    "        pet_mean.rename('PET_mm'),\n",
    "        aet_mean.rename('AET_mm'),\n",
    "        deficit_mean.rename('deficit_mm'),\n",
    "        runoff_mean.rename('runoff_mm'),\n",
    "        soil_mean.rename('soil_moisture_mm'),\n",
    "        vpd_mean.rename('VPD_kPa')\n",
    "    ])\n",
    "\n",
    "    # Extract to facilities\n",
    "    def reduce_feature(feat):\n",
    "        reduced = combined.reduceRegion(\n",
    "            reducer=ee.Reducer.mean(),\n",
    "            geometry=feat.geometry(),\n",
    "            scale=scale,\n",
    "            maxPixels=1e9\n",
    "        )\n",
    "        return feat.set(reduced)\n",
    "\n",
    "    return fc.map(reduce_feature)\n",
    "\n",
    "print(\"✓ TerraClimate extraction function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NGUTyIAJSDZt"
   },
   "outputs": [],
   "source": [
    "#@title Elevation from SRTM\n",
    "\n",
    "def extract_elevation(fc, scale):\n",
    "    \"\"\"\n",
    "    Extract elevation from SRTM\n",
    "    \"\"\"\n",
    "    srtm = ee.Image('USGS/SRTMGL1_003')\n",
    "    elevation = srtm.select('elevation')\n",
    "\n",
    "    # Extract to facilities\n",
    "    def reduce_feature(feat):\n",
    "        reduced = elevation.reduceRegion(\n",
    "            reducer=ee.Reducer.mean(),\n",
    "            geometry=feat.geometry(),\n",
    "            scale=scale,\n",
    "            maxPixels=1e9\n",
    "        )\n",
    "        return feat.set({'elevation_m': reduced.get('elevation')})\n",
    "\n",
    "    return fc.map(reduce_feature)\n",
    "\n",
    "print(\"✓ Elevation extraction function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wsHS4N9tSDZt"
   },
   "source": [
    "## Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m5JTyjjHSDZu"
   },
   "outputs": [],
   "source": [
    "#@title Extract all climate features (this may take several minutes)\n",
    "\n",
    "print(\"Starting feature extraction...\\n\")\n",
    "\n",
    "# Start with facilities\n",
    "fc_result = fc_facilities\n",
    "\n",
    "# 1. CHIRPS Precipitation\n",
    "print(\"[1/4] Extracting CHIRPS precipitation features...\")\n",
    "try:\n",
    "    fc_result = extract_chirps_features(fc_result, START_DATE, END_DATE, SCALE_METERS)\n",
    "    print(\"      ✓ CHIRPS complete\")\n",
    "except Exception as e:\n",
    "    print(f\"      ✗ CHIRPS failed: {e}\")\n",
    "\n",
    "# 2. ERA5-Land Temperature & Met\n",
    "print(\"[2/4] Extracting ERA5-Land temperature & meteorological features...\")\n",
    "try:\n",
    "    fc_result = extract_era5_features(fc_result, START_DATE, END_DATE, SCALE_METERS)\n",
    "    print(\"      ✓ ERA5-Land complete\")\n",
    "except Exception as e:\n",
    "    print(f\"      ✗ ERA5-Land failed: {e}\")\n",
    "\n",
    "# 3. TerraClimate Water Balance\n",
    "print(\"[3/4] Extracting TerraClimate water balance features...\")\n",
    "try:\n",
    "    fc_result = extract_terraclimate_features(fc_result, START_DATE, END_DATE, SCALE_METERS)\n",
    "    print(\"      ✓ TerraClimate complete\")\n",
    "except Exception as e:\n",
    "    print(f\"      ✗ TerraClimate failed: {e}\")\n",
    "\n",
    "# 4. Elevation\n",
    "print(\"[4/4] Extracting elevation...\")\n",
    "try:\n",
    "    fc_result = extract_elevation(fc_result, SCALE_METERS)\n",
    "    print(\"      ✓ Elevation complete\")\n",
    "except Exception as e:\n",
    "    print(f\"      ✗ Elevation failed: {e}\")\n",
    "\n",
    "print(\"\\n✓ All extractions complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jh8zzFn1SDZu"
   },
   "source": [
    "## Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8i7PxQUpSDZu"
   },
   "outputs": [],
   "source": [
    "#@title Convert to DataFrame and export\n",
    "\n",
    "print(\"Converting to DataFrame...\")\n",
    "\n",
    "# Get the feature collection info\n",
    "fc_info = fc_result.getInfo()\n",
    "\n",
    "# Extract properties from each feature\n",
    "rows = []\n",
    "for feat in fc_info['features']:\n",
    "    props = feat['properties']\n",
    "    rows.append(props)\n",
    "\n",
    "df_result = pd.DataFrame(rows)\n",
    "\n",
    "# Add metadata columns\n",
    "df_result['start_date'] = START_DATE\n",
    "df_result['end_date'] = END_DATE\n",
    "df_result['buffer_m'] = BUFFER_METERS\n",
    "df_result['scale_m'] = SCALE_METERS\n",
    "df_result['extraction_date'] = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "print(f\"\\n✓ Created DataFrame with {len(df_result)} facilities and {len(df_result.columns)} columns\")\n",
    "print(f\"\\nColumns: {df_result.columns.tolist()}\")\n",
    "print(f\"\\nSummary statistics:\")\n",
    "print(df_result.describe())\n",
    "\n",
    "# Show first few rows\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(df_result.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Oeej8GvHSDZu"
   },
   "outputs": [],
   "source": [
    "#@title Export to CSV\n",
    "\n",
    "# Generate filename\n",
    "timestamp = datetime.now().strftime('%Y%m%d')\n",
    "csv_filename = f\"{OUTPUT_PREFIX}_{timestamp}.csv\"\n",
    "\n",
    "# Save\n",
    "df_result.to_csv(csv_filename, index=False)\n",
    "\n",
    "print(f\"✓ Saved to {csv_filename}\")\n",
    "print(f\"\\nDownload the file:\")\n",
    "files.download(csv_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "00qk8RGRSDZu"
   },
   "outputs": [],
   "source": [
    "#@title Optional: Split by Category (INF/NCD)\n",
    "\n",
    "if 'Category' in df_result.columns:\n",
    "    # Split by category\n",
    "    for category in df_result['Category'].unique():\n",
    "        df_cat = df_result[df_result['Category'] == category]\n",
    "        cat_filename = f\"{OUTPUT_PREFIX}_{category.lower()}_{timestamp}.csv\"\n",
    "        df_cat.to_csv(cat_filename, index=False)\n",
    "        print(f\"✓ Saved {category}: {cat_filename} ({len(df_cat)} facilities)\")\n",
    "        files.download(cat_filename)\n",
    "else:\n",
    "    print(\"No 'Category' column found - skipping split export\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0xEDM8_XSDZu"
   },
   "source": [
    "## Feature Analysis & Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oFC0t1X8SDZv"
   },
   "outputs": [],
   "source": [
    "#@title Visualize climate feature distributions\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Select key climate features for visualization\n",
    "viz_features = [\n",
    "    'P_mean_mm', 'T_mean_C', 'DTR_C', 'PET_mm',\n",
    "    'VPD_kPa', 'elevation_m', 'wetday_frac', 'hot_days_per_year'\n",
    "]\n",
    "\n",
    "# Filter to available features\n",
    "viz_features = [f for f in viz_features if f in df_result.columns]\n",
    "\n",
    "if len(viz_features) >= 4:\n",
    "    fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, feat in enumerate(viz_features[:8]):\n",
    "        if i < len(axes):\n",
    "            df_result[feat].hist(ax=axes[i], bins=20, edgecolor='black')\n",
    "            axes[i].set_title(feat, fontsize=10)\n",
    "            axes[i].set_xlabel('')\n",
    "\n",
    "    # Hide unused subplots\n",
    "    for i in range(len(viz_features), len(axes)):\n",
    "        axes[i].set_visible(False)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('climate_feature_distributions.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    files.download('climate_feature_distributions.png')\n",
    "\n",
    "\n",
    "    print(\"✓ Feature distributions saved as 'climate_feature_distributions.png'\")\n",
    "else:\n",
    "    print(\"Not enough features available for visualization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_REKnaAGSDZv"
   },
   "outputs": [],
   "source": [
    "#@title Correlation matrix of climate features\n",
    "\n",
    "# Select numeric climate features\n",
    "numeric_cols = df_result.select_dtypes(include=[np.number]).columns\n",
    "# Exclude metadata\n",
    "climate_cols = [c for c in numeric_cols if c not in ['lat', 'lon', 'buffer_m', 'scale_m']]\n",
    "\n",
    "if len(climate_cols) > 3:\n",
    "    # Calculate correlation matrix\n",
    "    corr_matrix = df_result[climate_cols].corr()\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(\n",
    "        corr_matrix,\n",
    "        annot=True,\n",
    "        fmt='.2f',\n",
    "        cmap='RdBu_r',\n",
    "        center=0,\n",
    "        square=True,\n",
    "        linewidths=0.5,\n",
    "        cbar_kws={\"shrink\": 0.8}\n",
    "    )\n",
    "    plt.title('Climate Feature Correlation Matrix', fontsize=14, pad=20)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('climate_feature_correlations.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    print(\"✓ Correlation matrix saved as 'climate_feature_correlations.png'\")\n",
    "    files.download('climate_feature_correlations.png')\n",
    "else:\n",
    "    print(\"Not enough features for correlation analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tDkEDmoKSDZv"
   },
   "source": [
    "## K-Means Clustering Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S7LwJQQuSDZv"
   },
   "outputs": [],
   "source": [
    "#@title Preview k-means clustering (k=8)\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Select features for clustering\n",
    "cluster_features = [c for c in climate_cols if c in df_result.columns]\n",
    "\n",
    "if len(cluster_features) >= 3 and len(df_result) >= 8:\n",
    "    # Prepare data\n",
    "    X = df_result[cluster_features].values\n",
    "    X = np.nan_to_num(X, nan=np.nanmedian(X, axis=0))\n",
    "\n",
    "    # Standardize\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # K-means clustering\n",
    "    k = min(8, len(df_result))  # Use k=8 or fewer if limited facilities\n",
    "    kmeans = KMeans(n_clusters=k, n_init=20, random_state=42)\n",
    "    df_result['climate_k'] = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "    print(f\"✓ K-means clustering complete (k={k})\")\n",
    "    print(f\"\\nCluster sizes:\")\n",
    "    print(df_result['climate_k'].value_counts().sort_index())\n",
    "\n",
    "    # Visualize clusters in 2D (PCA)\n",
    "    from sklearn.decomposition import PCA\n",
    "\n",
    "    pca = PCA(n_components=2)\n",
    "    X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    scatter = plt.scatter(\n",
    "        X_pca[:, 0],\n",
    "        X_pca[:, 1],\n",
    "        c=df_result['climate_k'],\n",
    "        cmap='tab10',\n",
    "        s=100,\n",
    "        alpha=0.7,\n",
    "        edgecolors='black',\n",
    "        linewidth=0.5\n",
    "    )\n",
    "    plt.colorbar(scatter, label='Climate Cluster')\n",
    "    plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%} variance)')\n",
    "    plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%} variance)')\n",
    "    plt.title(f'Facility Climate Clusters (k={k})', fontsize=14)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('climate_clusters_pca.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    print(\"\\n✓ Cluster visualization saved as 'climate_clusters_pca.png'\")\n",
    "    files.download('climate_clusters_pca.png')\n",
    "\n",
    "\n",
    "    # Export with cluster labels\n",
    "    csv_with_clusters = f\"{OUTPUT_PREFIX}_with_clusters_{timestamp}.csv\"\n",
    "    df_result.to_csv(csv_with_clusters, index=False)\n",
    "    print(f\"\\n✓ Exported with cluster labels: {csv_with_clusters}\")\n",
    "    files.download(csv_with_clusters)\n",
    "\n",
    "else:\n",
    "    print(\"Insufficient data for clustering preview\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-dKVK11KSDZv"
   },
   "source": [
    "## Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dMPoZR6dSDZw"
   },
   "outputs": [],
   "source": [
    "#@title Generate summary report\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"CLIMATE FEATURE EXTRACTION SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nStudy Period: {START_DATE} to {END_DATE}\")\n",
    "print(f\"Number of facilities: {len(df_result)}\")\n",
    "print(f\"Buffer radius: {BUFFER_METERS}m\")\n",
    "print(f\"Spatial scale: {SCALE_METERS}m\")\n",
    "\n",
    "if 'Category' in df_result.columns:\n",
    "    print(f\"\\nFacilities by category:\")\n",
    "    for cat, count in df_result['Category'].value_counts().items():\n",
    "        print(f\"  {cat}: {count}\")\n",
    "\n",
    "print(f\"\\nClimate features extracted ({len(climate_cols)}):\")\n",
    "for i, col in enumerate(climate_cols, 1):\n",
    "    print(f\"  {i:2d}. {col}\")\n",
    "\n",
    "print(f\"\\nMissing data:\")\n",
    "missing = df_result[climate_cols].isna().sum()\n",
    "if missing.sum() == 0:\n",
    "    print(\"  None - all features extracted successfully!\")\n",
    "else:\n",
    "    for col, count in missing[missing > 0].items():\n",
    "        print(f\"  {col}: {count} missing ({count/len(df_result)*100:.1f}%)\")\n",
    "\n",
    "if 'climate_k' in df_result.columns:\n",
    "    print(f\"\\nClimate regime distribution (k={df_result['climate_k'].nunique()}):\")\n",
    "    for cluster, count in df_result['climate_k'].value_counts().sort_index().items():\n",
    "        print(f\"  Cluster {cluster}: {count} facilities ({count/len(df_result)*100:.1f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"✓ Extraction complete! Files ready for HSA delineation.\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5v36G3SfYJwh"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
